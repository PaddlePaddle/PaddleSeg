_base_: '../_base_/cityscapes.yml'

batch_size: 3 # total batch size:  4 * 3
iters: 120000

train_dataset:
  transforms:
    - type: ResizeStepScaling
      min_scale_factor: 0.5
      max_scale_factor: 2.0
      scale_step_size: 0.25
    - type: RandomPaddingCrop
      crop_size: [1024, 512]
    - type: RandomHorizontalFlip
    - type: RandomDistort
      brightness_range: 0.4
      contrast_range: 0.4
      saturation_range: 0.4
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

val_dataset:
  transforms:
    - type: Resize
      target_size: [2048, 1024]
      keep_ratio: True
    - type: Normalize
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

optimizer:
  _inherited_: False
  type: AdamW
  beta1: 0.9
  beta2: 0.999
  weight_decay: 0.0125

lr_scheduler:
  _inherited_: False
  type: PolynomialDecay
  learning_rate: 4.0e-4
  power: 1.
  end_lr: 1.0e-6
  warmup_iters: 1500
  warmup_start_lr: 1.0e-6

loss:
  types:
    - type: CrossEntropyLoss
  coef: [1, 0.4]

model:
  type: RTFormer
  base_channels: 32
  head_channels: 64
  use_injection: [True, True]
  pretrained: https://paddleseg.bj.bcebos.com/dygraph/backbone/rtformer_slim_backbone_imagenet_pretrained.zip