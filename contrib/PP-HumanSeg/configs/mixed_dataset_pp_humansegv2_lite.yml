batch_size: 16   # total: 32
iters: 200000
save_interval: 1000

train_roots:
  - data/portrait14k
  - data/maadaa
  - data/matting_human_half
  - data/humanseg

train_data_ratio:
  - 8
  - 5
  - 1
  - 1

val_roots:
  - data/portrait14k
  - data/maadaa

dataset_weights:
  - 0.5
  - 0.5
  - 0
  - 0

class_weights:
  - 0.5
  - 0.5

train_transforms:
  - type: PaddingByAspectRatio
    aspect_ratio: 1.77777778
  - type: Resize
    target_size: [256, 144]
  - type: ResizeStepScaling
    scale_step_size: 0
  - type: RandomRotation
  - type: RandomPaddingCrop
    crop_size: [256, 144]
  - type: RandomHorizontalFlip
  - type: RandomDistort
  - type: RandomBlur
    prob: 0.3
  - type: Normalize

val_transforms:
  - type: Resize
    target_size: [256, 144]
  - type: Normalize

export:
  transforms:
    - type: Resize
      target_size: [256, 144]
    - type: Normalize

optimizer:
  type: sgd
  momentum: 0.9
  weight_decay: 0.0005

lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.01
  end_lr: 0
  power: 0.9

loss:
  types:
    - type: MixedLoss
      losses:
        - type: CrossEntropyLoss
        - type: LovaszSoftmaxLoss
      coef: [0.8, 0.2]
  coef: [1, 1, 1]


model:
  type: MobileSeg
  num_classes: 2
  backbone:
    type: MobileNetV3_large_x1_0  # out channels: [24, 40, 112, 160]
    pretrained: https://paddleseg.bj.bcebos.com/dygraph/backbone/mobilenetv3_large_x1_0_ssld.tar.gz
  cm_bin_sizes: [1, 2, 4]
  backbone_indices: [0, 1, 2]
  cm_out_ch: 128
  arm_out_chs: [32, 64, 128]
  seg_head_inter_chs: [16, 32, 32]
  use_last_fuse: True
