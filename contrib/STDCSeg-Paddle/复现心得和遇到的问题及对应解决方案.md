
## 论文复现总结

本次百度论文复现挑战赛题目29Rethinking BiSeNet For Real-time Semantic Segmentation(CVPR2021)”（STDCSeg）的复现得到了百度飞浆平台和工作人员的大力支持，非常感谢！

该论文是计算机视觉顶级会议CVPR2021的会议论文，论文对之前流行的用于实时分割的two-stream网络BiSeNet进行了思考：其增加一个额外的路径来编码空间信息的原理是很耗时的，而且由于缺乏特定任务的设计，从预训练的任务（如图像分类）中借用的骨干可能对图像分割是低效的。
针对上述挑战，作者消除结构冗余，提出一种新型高效结构STDC结构。具体来说，作者逐步降低特征图的维度，并利用它们的聚合来表示图像，以此形成 STDC 网络的基本模块。在解码器中，通过将空间信息的学习以 single-stream 的方式整合到低层，提出一个 Detail Aggregation 模块。最后，低层特征和深层特征被融合以预测最终的分割结果。

从原始论文的数据来看，该论文提出的算法实现了高效且高精度的分割效果。同时论文提供了开源的代码，是一篇值得复现且很便利的论文。

- **复现结果**:
Backbone利用ImageNet上的预训练Pytorch模型参数转为Paddle模型参数，采用80000 iter，batch_size=36，base_lr=0.01 warmup+poly的学习率策略，STDCNet2-Seg50模型在Cityscaps VAL数据集上达到了74.62的mIOU。

## 问题及对应解决方案

在复现的过程中，也遇到了一些比较关键的问题。现我将其整理如下：

### 1、Backbone缺乏预训练模型

因为原论文的backbone是自己设计的STDC模型搭建。论文为测试该STDCNet的分类性能，事先在ImageNet数据集上进行了训练。分割模型则基于此预训练模型进行训练。
而我在利用paddle进行模型的编写后，一开始并没有采用预训练模型。因为在ImageNet上进行重新训练的代价是巨大的，仅仅利用AiStudio进行训练需要消耗大量时间和精力。并且我的算力时常不够哈哈哈哈。
所以一开始是直接在cityscapes上进行训练的。这也查阅了相关文献（何凯明2019年关于预训练重要性的一篇论文），该论文认为预训练模型可以加快模型的收敛，但是对结果影响不会很大。

**但是我的实验结果表明**：
Backbone无ImageNet上预训练的模型，在60000 iters, batch_size = 32，0.01 poly（原论文60000 iters，batch_size=48，warmup+poly，有ImageNet预训练模型）的情况下，STDCNet2-Seg50模型在Cityscaps VAL数据集上达到了67.72的best mIOU。继续用该训模型进行进一步训练，60000 iters，batch_size = 32，0.001 poly, STDCNet2-Seg50模型在Cityscaps VAL数据集上达到了69.47的best mIOU。

可以看出，结果离论文结果相差很多。我在向作者在github的issues求证以后，得到的回复是**预训练模型很重要！！！**
因为cityscapes的数据量很小！！！这说明对于小数据量的数据集，预训练模型是很有益的。后面的实验结果也证实了这一点。

**解决方案**：将论文提供的pytorch风格的backbone预训练模型参数转换成paddle风格。这部分的代码：
```python
def convert_params(params_path):
    '''
    convert torch style model param to paddle.
    '''
    import torch
    import paddle
    params = torch.load(params_path, map_location=torch.device('cpu'))
    new_params = dict()
    bn_w_name_list = list()
    for k, v in params.items():
        print(k,v)
        if k.endswith(".running_mean"):
            new_params[k.replace(".running_mean", "._mean")] = v.detach().numpy(
            )
        elif k.endswith(".running_var"):
            new_params[k.replace(".running_var", "._variance")] = v.detach(
            ).numpy()
            bn_w_name_list.append(k.replace(".running_var", ".weight"))
        else:
            new_params[k] = v.detach().numpy()
    for k, v in new_params.items():
        if len(v.shape) == 2 and k.endswith(
                ".weight") and k not in bn_w_name_list:
            new_params[k] = v.T
    paddle.save(new_params,
                params_path.replace(".pth", ".pdiparams").replace(
                    ".pt", ".pdiparams").replace(".ckpt", ".pdiparams"))
```
Note：实际上转换后并直接load到模型的backbone上只拿到了卷积权重，丢失了一些奇奇怪怪的参数...反正就是只能用来当预训练权重，不能拿去做分类。
### 2、paddle与torch的风格不一致问题
- 卷积\ReLu\BN等代码：torch是Conv2d，paddle是Conv2D。 也就是大小写转换。
- ModuleList转换：torch中的ModuleList，paddle里面没有。应该换成LayerList。
- torch：nn.Module 对应paddle：nn.Layer
- paddle中没有view函数：用reshape代替。
- paddle中的数据类型不能用.float()这样的形式，可以写成.astype(‘float32‘)风格。


- 创建可学习参数：

torch：
```
self.fuse_kernel = torch.nn.Parameter(torch.tensor([[6./10], [3./10], [1./10]],
    dtype=torch.float32).reshape(1, 3, 1, 1).type(torch.cuda.FloatTensor))
```

paddle(因为是可学习参数，所以没有赋值):
```
paddle.create_parameter([1,3,1,1],dtype='float32')
```

- 创建mask，paddle不支持以下torch的代码风格：

torch：
```
        boundary_targets[boundary_targets > 0.1] = 1
        boundary_targets[boundary_targets <= 0.1] = 0
```
paddle：
```
        boundary_targets = boundary_targets>0.1
        boundary_targets = boundary_targets.astype('float32')
```

其他都是一些api对应的小问题了，思路是先查询torch该api的作用，然后在paddle的官方api文档进行检索。

### 3、warmup学习率调整策略
这部分paddle中还没有。只能自己写一个：
```python

from paddle.optimizer.lr import LinearWarmup
from paddle.optimizer.lr import PolynomialDecay


class PolyDecay(PolynomialDecay):
    def __init__(self, lr, power, decay_steps, end_lr,cycle=False,**kwargs):
        super(PolyDecay, self).__init__(
            learning_rate=lr,
            power = power,
            decay_steps = decay_steps,
            end_lr = end_lr,
            cycle = cycle
            )
        self.update_specified = False

class Warmup_PolyDecay(LinearWarmup):

    def __init__(self, lr_rate,warmup_steps,iters,warmup_strat_lr = 1e-5,end_lr=1e-5,power=0.9,cycle = False,**kwargs):
        assert iters > warmup_steps, "total epoch({}) should be larger than warmup_epoch({}) in WarmupPolyDecay.".format(iters, warmup_steps)
        warmup_steps = warmup_steps
        start_lr = warmup_strat_lr
        end_lr = end_lr
        warmup_end_lr = lr_rate
        lr_sch = PolyDecay(lr = lr_rate,end_lr=end_lr, decay_steps= iters-warmup_steps,power=power,cycle=cycle)

        super(Warmup_PolyDecay, self).__init__(
            learning_rate=lr_sch,
            warmup_steps=warmup_steps,
            start_lr=start_lr,
            end_lr=warmup_end_lr)

        self.update_specified = False
```

以上基本是在论文复现中遇到的问题。可能还有一些小问题没有列出来。
总的来说，整个复现过程收获很多。
一个是对原始论文有了更深入的认识，一个是代码的阅读能力有所提升，其次是查阅文档的能力以及实践能力得到锻炼。
对paddlepaddle也有了更多的认识，百度提供了很优质的开发库和文档，用起来很方便。虽然还处于开发阶段，但相信不久后能成为广为使用的一个框架。
再次感谢百度飞浆团队的支持！

2021-08-27 xbchen(email:joyful_chen@163.com)