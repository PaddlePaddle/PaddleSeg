English | [简体中文](README_CN.md)

# Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision

Unlike image classification tasks, **data annotation is relatively difficult and costly for semantic segmentation tasks**. It is necessary to label each pixel of an image, including objects with special details, such as electric poles. However, obtaining RGB data is relatively simple. **How to use a large amount of unlabeled data to improve the performance of the model is a research issue in the field of semi supervised semantic segmentation**.

[Cross pseudo supervision, CPS](https://arxiv.org/abs/2106.01226) is a **very concise and high-performance** semi supervised semantic segmentation task algorithm. During training, two networks with the same structure but different initializations are used, and constraints are added to ensure that the outputs of the two networks for the same sample are similar. Specifically, the one hat pseudo label generated by the current network will serve as the target for another path of network prediction. This process can be monitored using cross entropy loss, just like the traditional supervision of fully supervised semantic segmentation tasks. **This algorithm has achieved SOTA results in both benchmarks (PASCAL VOC, Cityscapes)**

Some visualization results are as follows: RGB image on the left, prediction image in the middle, and true value on the right:

![](https://ai-studio-static-online.cdn.bcebos.com/e45cf14fe5a0417791a5455e84b2243abe8d8298cba94c8f9d98b0edd8a431d1)

![](https://ai-studio-static-online.cdn.bcebos.com/a136cff0ce7748dbb7bd3d8fa5b6942b8eeee8cb10ec456694c749a09375fc29)

## Contents
- [Installation](#Installation)
- [Models](#Models)
- [Dataset Preparation](#Dataset-Preparation)
- [Training, Evaluation and Prediction](#Training-Evaluation-and-Prediction)

## Installation

- [PaddlePaddle Installation](https://www.paddlepaddle.org.cn/install/quick)
    - Versions：PaddlePaddle develop, Python>=3.7

- PaddleSeg Installation, use the following command:

```shell
git clone -b develop https://github.com/PaddlePaddle/PaddleSeg
cd PaddleSeg
pip install -r requirements.txt
pip install -v -e .
```

## Models

The results reproduced in this project are 50% of the labeled Cityscapes dataset, and the mIOU of the reproduced model is **78.39%**. The comparison is shown in the following table:

| CPS.resnet50.deeplabv3+(1/2 Cityscapes) | mIOU |
| --- | --- |
| pytorch | 78.77% |
| paddle | 78.39% |

The model weight download link for Paddle replication is:

## Dataset-Preparation

The Cityscapes dataset provided using the CPS source code has been uploaded to [AI Studio](https://aistudio.baidu.com/aistudio/datasetdetail/177911). We recommended decompressing the data to the `contrib/CrossPseudoService/data` folder. The prepared data is organized as follows:

```
data/
|-- city
    ├── config_new
    │    ├── coarse_split
    │    │   ├── train_extra_3000.txt
    │    │   ├── train_extra_6000.txt
    │    │   └── train_extra_9000.txt
    │    ├── subset_train
    │    │   ├── train_aug_labeled_1-16.txt
    │    │   ├── train_aug_labeled_1-2.txt
    │    │   ├── train_aug_labeled_1-4.txt
    │    │   ├── train_aug_labeled_1-8.txt
    │    │   ├── train_aug_unlabeled_1-16.txt
    │    │   ├── train_aug_unlabeled_1-2.txt
    │    │   ├── train_aug_unlabeled_1-4.txt
    │    │   └── train_aug_unlabeled_1-8.txt
    │    ├── test.txt
    │    ├── train.txt
    │    ├── train_val.txt
    │    └── val.txt  
    ├── generate_colored_gt.py
    ├── images
    │   ├── test
    │   ├── train
    │   └── val
    └── segmentation
        ├── test
        ├── train
        └── val
```

## Training-Evaluation-and-Prediction

Execute the following command to enter the branch where `CPS` is located:
```shell
cd ./contrib/CrossPseudoSupervision
```

### Training

After preparing the environment and data, execute the following command training:

```shell
python train.py --config ./configs/deeplabv3p/deeplabv3p_resnet50_0.5cityscapes_800x800_240e.yml --log_iters 10 --save_dir ./output/ --batch_size 2
```

We recommend using a single machine with multiple cards for training. Execute the following command to start four card training:

```shell
python -m paddle.distributed.launch --gpus="0,1,2,3" train.py --config ./configs/deeplabv3p/deeplabv3p_resnet50_0.5cityscapes_800x800_240e.yml \
--log_iters 10 --save_dir $SAVE_PATH$ --batch_size 8
```

**Note**: The training process in the original repo of the paper is not validated, but rather the accuracy of the remaining saved weights will be tested one by one after the training is completed, so this project will not be validated during the training process either; The configuration file is training for 1/2 labeled data. To change to another ratio, the number of training epochs needs to be adjusted:

| Dataset    | 1/16 | 1/8  | 1/4  | 1/2  |
| ---------- | ---- | ---- | ---- | ---- |
| Cityscapes | 128  | 137  | 160  | 240  |

### Evaluation

After training, execute the following command to evaluate the model accuracy:

```shell
export CUDA_VISIBLE_DEVICES=0
python val.py \
       --config ./configs/deeplabv3p/deeplabv3p_resnet50_0.5cityscapes_800x800_240e.yml \
       --model_path $MODEL_PATH$
```

### Prediction

```shell
export CUDA_VISIBLE_DEVICES=0
!python predict.py \
       --config ./configs/deeplabv3p/deeplabv3p_resnet50_0.5cityscapes_800x800_240e.yml \
       --model_path $MODEL_PATH$ \
       --image_path $IMG_PATH$ \
       --save_dir $SAVE_PATH$ \
       --is_slide \
       --crop_size 800 800 \
       --stride 532 532
```

You can directly download the model provided by us for prediction.
