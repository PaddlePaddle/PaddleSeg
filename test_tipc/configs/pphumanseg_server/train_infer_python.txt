===========================train_params===========================
model_name:pphumanseg_server
python:python3.7
gpu_list:0|0,1
--device:gpu
Global.auto_cast:null
--iters:lite_train_lite_infer=20|lite_train_whole_infer=20|whole_train_whole_infer=1000
--save_dir:
--batch_size:lite_train_lite_infer=2|lite_train_whole_infer=2|whole_train_whole_infer=8
--model_path:null
train_model_name:best_model/model.pdparams
train_infer_img_dir:test_tipc/data/mini_supervisely/test.txt
--profiler_options:null
##
trainer:norm_train
norm_train:tools/train.py --config test_tipc/configs/pphumanseg_server/human_pp_humansegv1_server.yml --device gpu --save_interval 500 --seed 100 --num_workers 24
pact_train:null
fpgm_train:null
distill_train:null
null:null
null:null
##
===========================eval_params===========================
eval:null
null:null
##
===========================export_params===========================
--save_dir:
--model_path:
norm_export:tools/export.py --config test_tipc/configs/pphumanseg_server/human_pp_humansegv1_server.yml
quant_export:null
fpgm_export:null
distill_export:null
export1:null
export2:null
===========================infer_params===========================
infer_model:./test_tipc/output/pphumanseg_server/pphumanseg_server_generic_192x192/model.pdparams
infer_export:tools/export.py --config test_tipc/configs/pphumanseg_server/human_pp_humansegv1_server.yml
infer_quant:False
inference:deploy/python/infer.py
--device:cpu|gpu
--enable_mkldnn:True
--cpu_threads:6
--batch_size:1
--use_trt:False
--precision:fp32
--config:
--image_path:./test_tipc/data/mini_supervisely/test.txt
--save_log_path:null
--benchmark:True
--save_dir:
--model_name:pphumanseg_server
===========================infer_benchmark_params==========================
random_infer_input:[{float32,[3,512,512]}]
===========================to_static_train_benchmark_params===========================
to_static_train:--opts to_static_training=True
===========================train_benchmark_params==========================
batch_size:4
fp_items:fp32|fp16
epoch:400
--profiler_options:'batch_range=[10,20];state=GPU;tracer_option=Default;profile_path=model.profile'  
flags:FLAGS_eager_delete_tensor_gb=0.0;FLAGS_fraction_of_gpu_memory_to_use=0.98;FLAGS_conv_workspace_size_limit=4096;FLAGS_cudnn_deterministic=False
log_iters:15;repeats:500
